{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "#from pathsWY import *\n",
    "#from SM_tools import *\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "import requests\n",
    "import glob\n",
    "import ulmo\n",
    "from xgrads import open_CtlDataset\n",
    "from shapely import geometry as sgeom\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# User inputs\n",
    "#########################################################################\n",
    "\n",
    "domain = 'CA'\n",
    "\n",
    "\n",
    "#select the water year of interest \n",
    "water_year = 2019\n",
    "\n",
    "#start date\n",
    "stdt = str(water_year -1) +'-10-01'\n",
    "#end date\n",
    "eddt = str(water_year)+'-09-30'\n",
    "\n",
    "#path to SM output .gdat files\n",
    "gdatPath = r\"/scratch/Nina/CSOdata/\"+domain+\"/\"\n",
    "# path to output .nc files\n",
    "assim_file_path = r\"/nfs/attic/dfh/Aragon2/CSOassim/\"+domain+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# SNOTEL Functions\n",
    "#########################################################################\n",
    "# functions to get snotel data in each domain to compare to SM outputs\n",
    "\n",
    "# functions to get SNOTEL stations as geodataframe\n",
    "def sites_asgdf(ulmo_getsites, stn_proj):\n",
    "    \"\"\" Convert ulmo.cuahsi.wof.get_sites response into a point GeoDataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Note: Found one SNOTEL site that was missing the location key\n",
    "    sites_df = pd.DataFrame.from_records([\n",
    "        OrderedDict(code=s['code'], \n",
    "        longitude=float(s['location']['longitude']), \n",
    "        latitude=float(s['location']['latitude']), \n",
    "        name=s['name'], \n",
    "        elevation_m=s['elevation_m'])\n",
    "        for _,s in ulmo_getsites.items()\n",
    "        if 'location' in s\n",
    "    ])\n",
    "\n",
    "    sites_gdf = gpd.GeoDataFrame(\n",
    "        sites_df, \n",
    "        geometry=gpd.points_from_xy(sites_df['longitude'], sites_df['latitude']),\n",
    "        crs=stn_proj\n",
    "    )\n",
    "    return sites_gdf\n",
    "\n",
    "def get_snotel_stns(domain):\n",
    "    \n",
    "    #path to CSO domains\n",
    "    domains_resp = requests.get(\"https://raw.githubusercontent.com/snowmodel-tools/preprocess_python/master/CSO_domains.json\")\n",
    "    domains = domains_resp.json()\n",
    "\n",
    "    #Snotel bounding box\n",
    "    Bbox = domains[domain]['Bbox']\n",
    "\n",
    "    # Snotel projection\n",
    "    stn_proj = domains[domain]['stn_proj']\n",
    "    # model projection\n",
    "    mod_proj = domains[domain]['mod_proj']\n",
    "\n",
    "    # Convert the bounding box dictionary to a shapely Polygon geometry using sgeom.box\n",
    "    box_sgeom = sgeom.box(Bbox['lonmin'], Bbox['latmin'], Bbox['lonmax'], Bbox['latmax'])\n",
    "    box_gdf = gpd.GeoDataFrame(geometry=[box_sgeom], crs=stn_proj)\n",
    "    \n",
    "    # WaterML/WOF WSDL endpoint url \n",
    "    if domain == 'NH':\n",
    "        wsdlurl = \"https://hydroportal.cuahsi.org/Scan/cuahsi_1_1.asmx?WSDL\"\n",
    "    else:\n",
    "        wsdlurl = \"https://hydroportal.cuahsi.org/Snotel/cuahsi_1_1.asmx?WSDL\"\n",
    "\n",
    "    # get dictionary of snotel sites \n",
    "    sites = ulmo.cuahsi.wof.get_sites(wsdlurl,user_cache=True)\n",
    "\n",
    "    #turn sites to geodataframe \n",
    "    snotel_gdf = sites_asgdf(sites,stn_proj)\n",
    "    \n",
    "    #clip snotel sites to domain bounding box\n",
    "    gdf = gpd.sjoin(snotel_gdf, box_gdf, how=\"inner\")\n",
    "    gdf.drop(columns='index_right', inplace=True)\n",
    "    gdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #add columns with projected coordinates \n",
    "    CSO_proj = gdf.to_crs(mod_proj)\n",
    "    gdf['easting'] = CSO_proj.geometry.x\n",
    "    gdf['northing'] = CSO_proj.geometry.y\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "\n",
    "def fetch(sitecode, variablecode, domain,start_date, end_date):\n",
    "    print(sitecode, variablecode, domain,start_date, end_date)\n",
    "    values_df = None\n",
    "    # WaterML/WOF WSDL endpoint url \n",
    "    if domain == 'NH':\n",
    "        wsdlurl = \"https://hydroportal.cuahsi.org/Scan/cuahsi_1_1.asmx?WSDL\"\n",
    "        network = 'SCAN:'\n",
    "    else:\n",
    "        wsdlurl = \"https://hydroportal.cuahsi.org/Snotel/cuahsi_1_1.asmx?WSDL\"\n",
    "        network = 'SNOTEL:'\n",
    "\n",
    "    try:\n",
    "        #Request data from the server\n",
    "        site_values = ulmo.cuahsi.wof.get_values(\n",
    "            wsdlurl, network+sitecode, variablecode, start=start_date, end=end_date\n",
    "        )\n",
    "        #Convert to a Pandas DataFrame   \n",
    "        values_df = pd.DataFrame.from_dict(site_values['values'])\n",
    "        #Parse the datetime values to Pandas Timestamp objects\n",
    "        values_df['datetime'] = pd.to_datetime(values_df['datetime'])\n",
    "        #Set the DataFrame index to the Timestamps\n",
    "        values_df.set_index('datetime', inplace=True)\n",
    "        #Convert values to float and replace -9999 nodata values with NaN\n",
    "        values_df['value'] = pd.to_numeric(values_df['value']).replace(-9999, np.nan)\n",
    "        #Remove any records flagged with lower quality\n",
    "        values_df = values_df[values_df['quality_control_level_code'] == '1']\n",
    "    except:\n",
    "        print(\"Unable to fetch %s\" % variablecode)\n",
    "    \n",
    "    return values_df\n",
    "\n",
    "def get_snotel_data(gdf,sddt, eddt,var,domain,units='metric'):\n",
    "    '''\n",
    "    gdf - pandas geodataframe of SNOTEL sites\n",
    "    st_dt - start date string 'yyyy-mm-dd'\n",
    "    ed_dt - end date string 'yyyy-mm-dd'\n",
    "    var - snotel variable of interest \n",
    "    units - 'metric' (default) or 'imperial'\n",
    "    '''\n",
    "    stn_data = pd.DataFrame(index=pd.date_range(start=stdt, end=eddt))\n",
    "    if domain == 'NH':\n",
    "        network = 'SCAN:'\n",
    "    else:\n",
    "        network = 'SNOTEL:'    \n",
    "\n",
    "    for sitecode in gdf.code:\n",
    "        try:\n",
    "            data = fetch(sitecode,network+var+'_D', domain, start_date=stdt, end_date=eddt)\n",
    "            #check for nan values\n",
    "            if len(data.value[np.isnan(data.value)]) > 0:\n",
    "                #check if more than 10% of data is missing\n",
    "                if len(data.value[np.isnan(data.value)])/len(data) > .02:\n",
    "                    print('More than 2% of days missing')\n",
    "                    gdf.drop(gdf.loc[gdf['code']==sitecode].index, inplace=True)\n",
    "                    continue\n",
    "                if np.mean(data) < 0:\n",
    "                    print('Average swe is <=0, removing station')\n",
    "                    gdf.drop(gdf.loc[gdf['code']==sitecode].index, inplace=True)\n",
    "                    continue                    \n",
    "            stn_data[sitecode] = data.value\n",
    "        except:\n",
    "            gdf.drop(gdf.loc[gdf['code']==sitecode].index, inplace=True)     \n",
    "    \n",
    "    gdf.reset_index(drop=True, inplace=True)\n",
    "    if units == 'metric':\n",
    "        if (var == 'WTEQ') |(var == 'SNWD') |(var == 'PRCP') |(var == 'PREC'):\n",
    "            #convert SNOTEL units[in] to [m]\n",
    "            for sitecode in gdf.code:\n",
    "                stn_data[sitecode] = 0.0254 * stn_data[sitecode]\n",
    "        elif (var == 'TAVG') |(var == 'TMIN') |(var == 'TMAX') |(var == 'TOBS'):\n",
    "            #convert SNOTEL units[F] to [C]\n",
    "            for sitecode in gdf.code:\n",
    "                stn_data[sitecode] = (stn_data[sitecode] - 32) * 5/9\n",
    "    return gdf, stn_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute model performance metrics\n",
    "def calc_metrics(mod_swe,stn_swe):\n",
    "    swe_stats = []\n",
    "    \n",
    "    #remove days with zero SWE at BOTH the station and the SM pixel\n",
    "    idx = np.where((stn_swe != 0) | (mod_swe != 0))\n",
    "    mod_swe = mod_swe[idx]\n",
    "    stn_swe = stn_swe[idx]\n",
    "\n",
    "    #remove days where station has nan values \n",
    "    idx = np.where(~np.isnan(stn_swe))\n",
    "    mod_swe = mod_swe[idx]\n",
    "    stn_swe = stn_swe[idx]\n",
    "    \n",
    "    if (np.mean(mod_swe) < 0):\n",
    "        print('undefined point in SnowModel')\n",
    "        swe_stats = [np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "    else:\n",
    "        #R-squared value - coefficient of determination \n",
    "        r = r2_score(stn_swe, mod_swe)\n",
    "        swe_stats.append(r)\n",
    "\n",
    "        #mean bias error\n",
    "        mbe = (sum(mod_swe - stn_swe))/mod_swe.shape[0]\n",
    "        swe_stats.append(mbe)\n",
    "\n",
    "        #root mean squared error\n",
    "        rmse = np.sqrt((sum((mod_swe - stn_swe)**2))/mod_swe.shape[0])\n",
    "        swe_stats.append(rmse)\n",
    "\n",
    "        # Nash-Sutcliffe model efficiency coefficient, 1 = perfect, assumes normal data \n",
    "        nse_top = sum((mod_swe - stn_swe)**2)\n",
    "        nse_bot = sum((stn_swe - np.mean(stn_swe))**2)\n",
    "        nse = 1-(nse_top/nse_bot)\n",
    "        swe_stats.append(nse)\n",
    "\n",
    "        # Kling-Gupta Efficiency, 1 = perfect\n",
    "        kge_std = (np.std(mod_swe)/np.std(stn_swe))\n",
    "        kge_mean = (np.mean(mod_swe)/np.mean(stn_swe))\n",
    "        kge_r = np.corrcoef(stn_swe,mod_swe)[1,0]\n",
    "        kge = 1 - (np.sqrt((kge_r-1)**2)+((kge_std-1)**2)+(kge_mean-1)**2)\n",
    "        swe_stats.append(kge)   \n",
    "        \n",
    "    return swe_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to edit text files\n",
    "def replace_line(file_name, line_num, text):\n",
    "    ''' \n",
    "    file_name = file to edit\n",
    "    line_num = line number in file to edit\n",
    "    text = nex text to put in\n",
    "    '''\n",
    "    lines = open(file_name, 'r').readlines()\n",
    "    lines[line_num] = text\n",
    "    out = open(file_name, 'w')\n",
    "    out.writelines(lines)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the nearest easting and norting to pt in a raster\n",
    "def nearest_grid(ds, pt):\n",
    "    \"\"\"\n",
    "    Returns the nearest easting and norting to pt in a Dataset (ds).\n",
    "    \n",
    "    pt : input point, tuple (easting, northing)\n",
    "    output:\n",
    "        easting, northing\n",
    "    \"\"\"\n",
    "    if all(coord in list(ds.coords) for coord in ['lat', 'lon']):\n",
    "            df_loc = ds[['lon', 'lat']].to_dataframe().reset_index()\n",
    "    loc_valid = df_loc.dropna()\n",
    "    pts = loc_valid[['lon', 'lat']].to_numpy()\n",
    "    idx = distance.cdist([pt], pts).argmin()\n",
    "    return loc_valid['lon'].iloc[idx], loc_valid['lat'].iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract SM swe values at pixels co-located with stations\n",
    "# and computer performance metrics.\n",
    "# Data saved out as netcdfs\n",
    "def SM_eval(domain,stdt,eddt, gdatPath):  \n",
    "    #get domain info\n",
    "    domains_resp = requests.get(\"https://raw.githubusercontent.com/snowmodel-tools/preprocess_python/master/CSO_domains.json\")\n",
    "    domains = domains_resp.json()\n",
    "    \n",
    "    # execute functions to get snotel data\n",
    "    stn_gdf = get_snotel_stns(domain)\n",
    "    STNgdf, stn_swe_all = get_snotel_data(stn_gdf,stdt,eddt,'WTEQ',domain)\n",
    "\n",
    "    # list of SM swed files \n",
    "    target = gdatPath + r\"*.gdat\"\n",
    "    lens = 23+len(domain)\n",
    "    filenames = sorted([f[lens:-5] for f in glob.glob(target)])\n",
    "\n",
    "\n",
    "    # create an empty numpy array of dimensions \n",
    "    # [#ensemble_members #stations #timesteps]\n",
    "    data = np.empty([len(filenames), len(STNgdf), len(pd.date_range(stdt,eddt,freq='d'))])\n",
    "\n",
    "    # create an empty numpy array of dimensions \n",
    "    # [#ensemble_members #stations #metrics]\n",
    "    statsdata = np.empty([len(filenames), len(STNgdf), 5])\n",
    "\n",
    "    for f in range(len(filenames)):\n",
    "        print(f+1,' of', len(filenames))\n",
    "        ctlFile = gdatPath + r\"/swed.ctl\"\n",
    "        #baseline SM run \n",
    "        text = r\"DSET ^\"+filenames[f]+\".gdat\\n\"\n",
    "        replace_line(ctlFile, 0, text)\n",
    "        modswe = open_CtlDataset(ctlFile)\n",
    "\n",
    "        for i in range(len(STNgdf)):\n",
    "            nam = STNgdf.code[i]\n",
    "            print(nam)\n",
    "\n",
    "            # define point\n",
    "            pt = (STNgdf.to_crs(domains[domain]['mod_proj']).geometry[i].x,STNgdf.to_crs(domains[domain]['mod_proj']).geometry[i].y)\n",
    "\n",
    "            # get nearest easting and northing to SM output\n",
    "            long, lati = nearest_grid(modswe, pt)\n",
    "\n",
    "            # select SM grid cell and subset to point\n",
    "            mod = modswe.swed.sel(lon=long,lat=lati)\n",
    "\n",
    "            # select station observations\n",
    "            stn = stn_swe_all[STNgdf.code[i]].values\n",
    "\n",
    "            # calculate performance statistics\n",
    "            stats = calc_metrics(mod,stn)\n",
    "\n",
    "            # add SM data to data array \n",
    "            data[f,i,:] = mod.values\n",
    "\n",
    "            # add stats data to data array \n",
    "            statsdata[f,i,:] = stats\n",
    "\n",
    "    #save SM swe output as netcdf\n",
    "    date = pd.date_range(stdt,eddt,freq='d')\n",
    "    station = STNgdf['code'].values\n",
    "\n",
    "    SMswe = xr.DataArray(\n",
    "        data,\n",
    "        dims=('assim_run', 'station', 'date'), \n",
    "        coords={'assim_run': filenames, \n",
    "                'station': station, 'date': date})\n",
    "\n",
    "    SMswe.attrs['long_name']= 'Assimilation SWE at stations'\n",
    "    SMswe.attrs['standard_name']= 'assim_swe'\n",
    "\n",
    "    d = OrderedDict()\n",
    "    d['assim_run'] = ('assim_run', filenames)\n",
    "    d['station'] = ('station', station)\n",
    "    d['date'] = ('date', date)\n",
    "    d['swe'] = SMswe\n",
    "\n",
    "    ds = xr.Dataset(d)\n",
    "    ds.attrs['description'] = \"SnowModel swe at stations\"\n",
    "    ds.attrs['model_output'] = \"SWE [m]\"\n",
    "\n",
    "    ds.assim_run.attrs['standard_name'] = \"assimilation_run\"\n",
    "    ds.assim_run.attrs['axis'] = \"run_id\"\n",
    "\n",
    "    ds.station.attrs['long_name'] = \"station_id\"\n",
    "    ds.station.attrs['axis'] = \"station\"\n",
    "\n",
    "    ds.date.attrs['long_name'] = \"date\"\n",
    "    ds.date.attrs['axis'] = \"date\"\n",
    "\n",
    "    #save performance stats as netcdf\n",
    "    metrics = ['R2','MBE','RMSE','NSE','KGE']\n",
    "\n",
    "    assimstats = xr.DataArray(\n",
    "        statsdata,\n",
    "        dims=('assim_run', 'station', 'metrics'), \n",
    "        coords={'assim_run': filenames, \n",
    "                'station': station, 'metrics': metrics})\n",
    "\n",
    "    assimstats.attrs['long_name']= 'Performance metrics at stations'\n",
    "    assimstats.attrs['standard_name']= 'metrics'\n",
    "\n",
    "    dd = OrderedDict()\n",
    "    dd['assim_run'] = ('assim_run', filenames)\n",
    "    dd['station'] = ('station', station)\n",
    "    dd['metrics'] = ('metrics', metrics)\n",
    "    dd['score'] = assimstats\n",
    "\n",
    "    dss = xr.Dataset(dd)\n",
    "    dss.attrs['description'] = \"Performance metrics at stations\"\n",
    "    dss.attrs['model_output'] = \"R^2 MBE RMSE NSE KGE\"\n",
    "\n",
    "    dss.assim_run.attrs['standard_name'] = \"assimilation_run\"\n",
    "    dss.assim_run.attrs['axis'] = \"run_id\"\n",
    "\n",
    "    dss.station.attrs['long_name'] = \"station_id\"\n",
    "    dss.station.attrs['axis'] = \"station\"\n",
    "\n",
    "    dss.metrics.attrs['long_name'] = \"performance_metrics\"\n",
    "    dss.metrics.attrs['axis'] = \"metrics\"\n",
    "    \n",
    "    return ds, dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR\n",
      "1166_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n",
      "434_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n",
      "1025_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<suds.sax.document.Document object at 0x7faa9e358b70>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to fetch SNOTEL:WTEQ_D\n",
      "1024_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<suds.sax.document.Document object at 0x7faa9e2abfd0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to fetch SNOTEL:WTEQ_D\n",
      "976_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<suds.sax.document.Document object at 0x7faa9e50ec18>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to fetch SNOTEL:WTEQ_D\n",
      "526_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n",
      "545_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n",
      "614_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n",
      "619_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n",
      "719_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n",
      "733_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n",
      "1167_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n",
      "815_OR_SNTL SNOTEL:WTEQ_D OR 2018-10-01 2019-09-30\n"
     ]
    }
   ],
   "source": [
    "#domain_list = ['CA','CO_N','CO_S','OR','UT','WA','WA_SQ','WY']\n",
    "domain_list = ['OR']\n",
    "\n",
    "\n",
    "for domain in domain_list: \n",
    "    print(domain)\n",
    "    #path to SM output .gdat files\n",
    "    gdatPath = r\"/scratch/Nina/CSOdata/\"+domain+\"/\"\n",
    "    # path to output .nc files\n",
    "    assim_file_path = r\"/nfs/attic/dfh/Aragon2/CSOassim/\"+domain+\"/\"\n",
    "\n",
    "    # eval SM performance\n",
    "    ds, dss = SM_eval(domain,stdt,eddt, gdatPath)\n",
    "    \n",
    "    #output .nc file name/path\n",
    "    outfilepath = assim_file_path + 'assim_swe_'+str(water_year)+'.nc'\n",
    "    ds.to_netcdf(outfilepath, format='NETCDF4', engine='netcdf4')\n",
    "    #output .nc file name/path\n",
    "    outfilepath = assim_file_path + 'assim_stats_'+str(water_year)+'.nc'\n",
    "    dss.to_netcdf(outfilepath, format='NETCDF4', engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get domain info\n",
    "domains_resp = requests.get(\"https://raw.githubusercontent.com/snowmodel-tools/preprocess_python/master/CSO_domains.json\")\n",
    "domains = domains_resp.json()\n",
    "\n",
    "# execute functions to get snotel data\n",
    "stn_gdf = get_snotel_stns(domain)\n",
    "STNgdf, stn_swe_all = get_snotel_data(stn_gdf,stdt,eddt,'WTEQ',domain)\n",
    "\n",
    "# list of SM swed files \n",
    "target = gdatPath + r\"*.gdat\"\n",
    "lens = 23+len(domain)\n",
    "filenames = sorted([f[lens:-5] for f in glob.glob(target)])\n",
    "\n",
    "f=0\n",
    "ctlFile = gdatPath + r\"/swed.ctl\"\n",
    "#baseline SM run \n",
    "text = r\"DSET ^\"+filenames[f]+\".gdat\\n\"\n",
    "replace_line(ctlFile, 0, text)\n",
    "modswe = open_CtlDataset(ctlFile)\n",
    "\n",
    "# make a figure\n",
    "fig, axs = plt.subplots(nrows=len(STNgdf), figsize=(14, 2*len(STNgdf)), ncols=1, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .5, wspace=.5)\n",
    "\n",
    "for i in range(len(STNgdf)):\n",
    "    nam = STNgdf.code[i]\n",
    "    \n",
    "    # define point\n",
    "    pt = (STNgdf.to_crs(domains[domain]['mod_proj']).geometry[i].x,STNgdf.to_crs(domains[domain]['mod_proj']).geometry[i].y)\n",
    "\n",
    "    # get nearest easting and northing to SM output\n",
    "    long, lati = nearest_grid(modswe, pt)\n",
    "\n",
    "    # select SM grid cell and subset to point\n",
    "    mod = modswe.swed.sel(lon=long,lat=lati)\n",
    "\n",
    "    # select station observations\n",
    "    stn = stn_swe_all[STNgdf.code[i]].values\n",
    "    \n",
    "    # calculate performance statistics\n",
    "    stats = calc_metrics(mod,stn)\n",
    "    \n",
    "    axs[i].plot(mod,'r',label = 'SM swe [m]',alpha = .5)\n",
    "    axs[i].plot(stn,'b',label = 'station swe [m]',alpha = .5)\n",
    "    axs[i].set_title(nam+' '+str(stats[0]))\n",
    "    #axs[i].set_ylim([0, 2])\n",
    "    if i == 0:\n",
    "        axs[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snowmodelcal]",
   "language": "python",
   "name": "conda-env-snowmodelcal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
