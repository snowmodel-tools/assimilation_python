{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and save landscape characteristics associated with SNOTEL stations & CSO obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import *\n",
    "import richdem as rd\n",
    "from osgeo import gdal\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from Depth2SWE import swe_calc\n",
    "import pandas as pd\n",
    "from SM_tools import *\n",
    "import xarray as xr\n",
    "from affine import Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the years that will be assimilated \n",
    "st = ['2018-10-01','2019-10-01']\n",
    "ed = ['2019-09-30','2020-09-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract and save landscape characteristics \n",
    "# associated with SNOTEL stations\n",
    "def extract_meta(gdf,mod_proj,dem_path,lc_path):\n",
    "    '''\n",
    "    gdf = geodataframe of SNOTEL in the domain\n",
    "    \n",
    "    proj = projection of the modeling domain \n",
    "    \n",
    "    dem_path = path to digital elevation model of domain\n",
    "    \n",
    "    lc_path = path to nlcd landcover data of domain\n",
    "    '''\n",
    "    \n",
    "    new=gdf.to_crs(mod_proj)\n",
    "    \n",
    "    #add x y values to CSO gdf\n",
    "    gdf['x']=new.geometry.x\n",
    "    gdf['y']=new.geometry.y\n",
    "    \n",
    "    #build list of coordinates from point geodataframe\n",
    "    xy = list(map(list, zip(new.geometry.x,new.geometry.y)))\n",
    "    \n",
    "    #ELEVATION\n",
    "    # DEM data\n",
    "    src = rio.open(dem_path)\n",
    "    #with rio.open(dtm) as src:\n",
    "    elevation = src.read(1)\n",
    "\n",
    "    #sample dem\n",
    "    with rio.open(dem_path) as src:\n",
    "        gdf['dem_elev'] = [sample[0] for sample in src.sample(xy)]\n",
    "    #-----------------------------------------------------------    \n",
    "    #SLOPE\n",
    "    #read in data\n",
    "    ds = gdal.Open(dem_path);\n",
    "    data = np.array(ds.GetRasterBand(1).ReadAsArray());\n",
    "    rda = rd.rdarray(data, no_data=-9999);\n",
    "    slope = rd.TerrainAttribute(rda, attrib='slope_riserun');\n",
    "    #get indicies\n",
    "    with rio.open(dem_path) as src:\n",
    "        rows, cols = rio.transform.rowcol(src.transform, new.geometry.centroid.x, new.geometry.centroid.y)\n",
    "    #sample slope array\n",
    "    gdf['slope'] = slope[rows,cols]\n",
    "    \n",
    "    #-----------------------------------------------------------        \n",
    "    #ASPECT\n",
    "    aspect = rd.TerrainAttribute(rda, attrib='aspect');\n",
    "    \n",
    "    #4-aspect key\n",
    "    #0=N, 2=E, 4=S, 6=W, 8=flat\n",
    "    DIR=aspect\n",
    "    DIR[(DIR>=0) & (DIR<=45)]=0\n",
    "    DIR[(DIR>45) & (DIR<=135)]=2\n",
    "    DIR[(DIR>135) & (DIR<=225)]=4\n",
    "    DIR[(DIR>225) & (DIR<=315)]=6\n",
    "    DIR[(DIR>315) & (DIR<=360)]=0\n",
    "    DIR[slope < 0.5]=8\n",
    "    DIR.astype(int)\n",
    "    \n",
    "#     #8-aspect key\n",
    "#     #0=N, 1=NE, 2=E, 3=SE, 4=S, 5=SW, 6=W, 7=NW, 8=flat\n",
    "#     DIR=aspect\n",
    "#     DIR[(DIR>=0) & (DIR<=22.5)]=0\n",
    "#     DIR[(DIR>22.5) & (DIR<=67.5)]=1\n",
    "#     DIR[(DIR>67.5) & (DIR<=112.5)]=2\n",
    "#     DIR[(DIR>112.5) & (DIR<=157.5)]=3\n",
    "#     DIR[(DIR>157.5) & (DIR<=202.5)]=4\n",
    "#     DIR[(DIR>202.5) & (DIR<=247.5)]=5\n",
    "#     DIR[(DIR>247.5) & (DIR<=292.5)]=6\n",
    "#     DIR[(DIR>292.5) & (DIR<=337.5)]=7\n",
    "#     DIR[(DIR>337.5) & (DIR<=360)]=0\n",
    "#     DIR[slope < 0.5]=8\n",
    "#     DIR.astype(int)\n",
    "\n",
    "    #sample aspect array\n",
    "    gdf['aspect'] = DIR[rows,cols]\n",
    "    \n",
    "    #-----------------------------------------------------------    \n",
    "    #LANDCOVER\n",
    "    # LC data\n",
    "    src = rio.open(lc_path)\n",
    "    lc = src.read(1)\n",
    "\n",
    "    # reassign lc from NLCD to SM classes\n",
    "    DIR=DIR=np.empty([np.shape(lc)[0],np.shape(lc)[1]])\n",
    "    DIR[lc == 11 ]=24\n",
    "    DIR[lc == 12 ]=20\n",
    "    DIR[lc == 21 ]=21\n",
    "    DIR[lc == 22 ]=21\n",
    "    DIR[lc == 23 ]=21\n",
    "    DIR[lc == 24 ]=21\n",
    "    DIR[lc == 31 ]=18\n",
    "    DIR[lc == 41 ]=2\n",
    "    DIR[lc == 42 ]=1\n",
    "    DIR[lc == 43 ]=6\n",
    "    DIR[lc == 51 ]=6\n",
    "    DIR[lc == 52 ]=6\n",
    "    DIR[lc == 71 ]=12\n",
    "    DIR[lc == 72 ]=12\n",
    "    DIR[lc == 73 ]=12\n",
    "    DIR[lc == 74 ]=12\n",
    "    DIR[lc == 81 ]=23\n",
    "    DIR[lc == 82 ]=22\n",
    "    DIR[lc == 90 ]=9\n",
    "    DIR[lc == 95 ]=9\n",
    "    DIR.astype(int)\n",
    "\n",
    "    #sample lc\n",
    "    gdf['lc'] = DIR[rows,cols]    \n",
    "\n",
    "    #-----------------------------------------------------------    \n",
    "    #TERRAIN COMPLEXITY\n",
    "    # calculate terrain complexity \n",
    "    tc = ndimage.generic_filter(elevation, np.std, size=3)\n",
    "    # sample tc\n",
    "    gdf['tc'] = tc[rows,cols]\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract point index from gridded data\n",
    "\n",
    "def point_index_from_grid(gdf,dem_path):\n",
    "    # load geo raster and get pixel centers\n",
    "    da = xr.open_rasterio(dem_path)\n",
    "    transform = Affine.from_gdal(*da.transform)\n",
    "    nx, ny = da.sizes['x'], da.sizes['y']\n",
    "    x, y = transform * np.meshgrid(np.arange(nx)+0.5, np.arange(ny)+0.5)\n",
    "    \n",
    "    # put point data into projection of gridded data \n",
    "    new=gdf.to_crs(da.crs[6:])\n",
    "\n",
    "    #station index\n",
    "    x_idx = []\n",
    "    y_idx = []\n",
    "\n",
    "    for i in range(len(new)):\n",
    "        minx = abs(new.geometry.x[i]-da.x.values)\n",
    "        x=np.where(minx==min(abs(new.geometry.x[i]-da.x.values)))[0][0]\n",
    "        x_idx.append(x)\n",
    "        # flip y values to align with cartesian coordinates\n",
    "        miny = abs(new.geometry.y[i]-np.flip(da.y.values))\n",
    "        y=np.where(miny==min(abs(new.geometry.y[i]-np.flip(da.y.values))))[0][0]\n",
    "        y_idx.append(y)\n",
    "\n",
    "\n",
    "    gdf['x_idx']=x_idx\n",
    "    gdf['y_idx']=y_idx\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNOTEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/attic/dfh/Aragon2/CSOassim/WY/all_snotel_meta.geojson: No such file or directory\n",
      "driver GeoJSON does not support creation option ENCODING\n"
     ]
    }
   ],
   "source": [
    "snotel_gdf = extract_meta(gdf,mod_proj,dem_path,lc_path)\n",
    "snotel_gdf = point_index_from_grid(gdf,dem_path)\n",
    "# save \n",
    "out = assimPath + 'all_snotel_meta.geojson'\n",
    "snotel_gdf.to_file(out, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get swe timeseries for SNOTEL\n",
    "!! This needs to be fixed !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     swe = get_swe(snotel_gdf,st[i], ed[i])\n",
    "# #     # save \n",
    "# #     out = assimPath + 'snotel_swe_'+st[i][0:4]+'_'+ed[i][0:4]+'.geojson'\n",
    "# #     snotel_gdf.to_file(out, driver='GeoJSON')\n",
    "\n",
    "# #     out = outpath + 'SNOTEL_data_SWEDmeters2018-09-01_2019-09-30.csv'\n",
    "# # stn_swe.to_csv(out)\n",
    "# #     get_swe(gdf,st, ed)\n",
    "# swe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import math\n",
    "import random\n",
    "\n",
    "# create dataframe ov variables to cluster over\n",
    "# path = assimPath + 'all_snotel_meta.geojson'\n",
    "# snotel_gdf = gpd.read_file(path)\n",
    "data = snotel_gdf[[\"dem_elev\",\"slope\",\"lc\",\"tc\",\"longitude\",\"aspect\", \"latitude\"]]\n",
    "\n",
    "#number of cluster is 1/3 of the total sample size\n",
    "clusters = math.ceil(len(data)/3)\n",
    "  \n",
    "#run kmeans\n",
    "kmeans = KMeans(n_clusters = clusters)\n",
    "kmeans.fit(data,y=None)\n",
    "\n",
    "#add cluster assignment to snotel gdf\n",
    "snotel_gdf['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/attic/dfh/Aragon2/CSOassim/WY/eval_snotel_meta.geojson: No such file or directory\n",
      "driver GeoJSON does not support creation option ENCODING\n"
     ]
    }
   ],
   "source": [
    "#randomly sample 1 station from each cluster\n",
    "sample = []\n",
    "for value in np.unique(snotel_gdf.cluster):\n",
    "    sample.append(random.choice(snotel_gdf.index[snotel_gdf.cluster == value]))\n",
    "    \n",
    "#create evaluation gdf\n",
    "samp = snotel_gdf.iloc[sample,:]\n",
    "\n",
    "# save \n",
    "out = assimPath + 'eval_snotel_meta.geojson'\n",
    "samp.to_file(out, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/attic/dfh/Aragon2/CSOassim/WY/assim_snotel_sites.geojson: No such file or directory\n",
      "driver GeoJSON does not support creation option ENCODING\n"
     ]
    }
   ],
   "source": [
    "# save assimilation data and swe \n",
    "snotel_assim_sites = snotel_gdf[~snotel_gdf.code.isin(samp.code)]\n",
    "snotel_assim_sites.reset_index(inplace = True,drop=True)\n",
    "# save sites\n",
    "out = assimPath + 'assim_snotel_sites.geojson'\n",
    "snotel_assim_sites.to_file(out, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of CSO in daimain =  310\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/attic/dfh/Aragon2/CSOassim/WY/all_cso_2018_2019_meta.geojson: No such file or directory\n",
      "driver GeoJSON does not support creation option ENCODING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of CSO in daimain =  72\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n",
      "Warning! No geotransform defined. Choosing a standard one! (Top left cell's top let corner at <0,0>; cells are 1x1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/attic/dfh/Aragon2/CSOassim/WY/all_cso_2019_2020_meta.geojson: No such file or directory\n",
      "driver GeoJSON does not support creation option ENCODING\n"
     ]
    }
   ],
   "source": [
    "def get_cso(st, ed, Bbox):\n",
    "    #Issue CSO API observations request and load the results into a GeoDataFrame\n",
    "    params = {\n",
    "      \"bbox\": f\"{Bbox['lonmin']},{Bbox['latmax']},{Bbox['lonmax']},{Bbox['latmin']}\",\n",
    "      \"start_date\": st,\n",
    "      \"end_date\": ed,\n",
    "      \"format\": \"geojson\",\n",
    "      \"limit\": 5000,\n",
    "    }\n",
    "\n",
    "    csodata_resp = requests.get(\"https://api.communitysnowobs.org/observations\", params=params)\n",
    "    csodatajson = csodata_resp.json()\n",
    "    #turn into geodataframe\n",
    "    gdf = gpd.GeoDataFrame.from_features(csodatajson, crs=stn_proj)\n",
    "    \n",
    "    mask = (gdf['timestamp'] >= st) & (gdf['timestamp'] <= ed)\n",
    "    gdf = gdf.loc[mask]\n",
    "    gdf=gdf.reset_index(drop=True)\n",
    "    print('Total number of CSO in daimain = ',len(gdf))\n",
    "    \n",
    "    ingdf = extract_meta(gdf,mod_proj,dem_path,lc_path)\n",
    "    \n",
    "    #need to format data for Hs_to_SWE conversion\n",
    "    ingdf['dt'] = pd.to_datetime(ingdf['timestamp'], format='%Y-%m-%dT%H:%M:%S')\n",
    "    ingdf['dt'] = pd.to_datetime(ingdf['dt']).dt.date\n",
    "    ingdf['Y'] = pd.DatetimeIndex(ingdf['dt']).year\n",
    "    ingdf['M'] = pd.DatetimeIndex(ingdf['dt']).month\n",
    "    ingdf['D'] = pd.DatetimeIndex(ingdf['dt']).day\n",
    "    ingdf[\"LON\"] = ingdf.geometry.x\n",
    "    ingdf[\"LAT\"] = ingdf.geometry.y\n",
    "    ingdf=ingdf.drop(columns=['dt'])\n",
    "    \n",
    "    #convert snow depth to mm to input into density function\n",
    "    ingdf['H'] = ingdf.depth*10\n",
    "    ingdf.head()\n",
    "    \n",
    "    #Hs to SWE\n",
    "    SWE,DOY = swe_calc(ingdf.Y.values,ingdf.M.values,ingdf.D.values,ingdf.H.values,ingdf.LAT.values,ingdf.LON.values)\n",
    "    \n",
    "    #convert swe to m to input into SM\n",
    "    ingdf['swe']=SWE/1000\n",
    "    ingdf['doy']=DOY\n",
    "    return ingdf\n",
    "\n",
    "for i in range(len(st)):\n",
    "    \n",
    "    csogdf = get_cso(st[i], ed[i], Bbox)\n",
    "    csogdf = point_index_from_grid(gdf,dem_path)\n",
    "\n",
    "    # save \n",
    "    out = assimPath + 'all_cso_'+st[i][0:4]+'_'+ed[i][0:4]+'_meta.geojson'\n",
    "    csogdf.to_file(out, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snowmodelcal]",
   "language": "python",
   "name": "conda-env-snowmodelcal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
