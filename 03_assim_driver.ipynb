{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from SM_tools import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the water year of interest \n",
    "water_year = 2019\n",
    "\n",
    "#select the variable of interest\n",
    "var = 'elev'\n",
    "\n",
    "#date assim initiated - used for labeling output directory\n",
    "today = datetime.date.today()\n",
    "hoy = today.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "# snotel swe timeseries \n",
    "snotel_swe_all = pd.read_csv(dataPath + 'SNOTEL_data_SWEDmeters'+ str(water_year -1) +'-09-01_'+str(water_year)+'-09-30.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# swe timeseries of stations to be assimilated \n",
    "snotel_swe_assim = snotel_swe_all[np.intersect1d(snotel_swe_all.columns, snotel_assim_sites.code.values)]\n",
    "\n",
    "# cso geodataframe \n",
    "cso_gdf = gpd.read_file(dataPath+'all_cso_'+str(water_year -1) +'_'+str(water_year)+'_meta.geojson')\n",
    "cso_gdf['dt'] = pd.DatetimeIndex(cso_gdf['timestamp'])\n",
    "\n",
    "#add line to edit par to reflect assim year -> edit met file name and start year in par file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionalry of par variables\n",
    "with open('par_base.json') as f:\n",
    "    base = json.load(f)\n",
    "    \n",
    "#Edit the par file to set parameters with new values\n",
    "def edit_par(par_dict,parameter,new_value):\n",
    "    lines = open(parFile, 'r').readlines()\n",
    "    if par_dict[parameter][2] == 14 or par_dict[parameter][2] == 17 \\\n",
    "    or par_dict[parameter][2] == 18 or par_dict[parameter][2] == 19 \\\n",
    "    or par_dict[parameter][2] == 93 or par_dict[parameter][2] == 95 \\\n",
    "    or par_dict[parameter][2] == 97 or par_dict[parameter][2] == 100 \\\n",
    "    or par_dict[parameter][2] == 102 or par_dict[parameter][2] == 104 \\\n",
    "    or par_dict[parameter][2] == 107 or par_dict[parameter][2] == 108:\n",
    "        text = str(new_value)+'\\n'\n",
    "    else:\n",
    "        text = str(new_value)+'\\t\\t\\t!'+par_dict[parameter][1]\n",
    "    lines[par_dict[parameter][2]] = text\n",
    "    out = open(parFile, 'w')\n",
    "    out.writelines(lines)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_par(base,'iyear_init',str(water_year))\n",
    "edit_par(base,'met_input_fname','met/mm_WY_'+str(water_year -1)+'-'+str(water_year)+'.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run SM for CSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = gdat_out_path+str(water_year)+'assim_run'+hoy+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges: [1774.  2062.4 2350.8 2639.2 2927.6 3216. ]\n",
      "labels: [0 1 2 3 4]\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/attic/dfh/miniconda/envs/snowmodelcal/lib/python3.6/site-packages/geopandas/geodataframe.py:831: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev\n",
      "\n",
      " For a DATA ASSIMILATION RUN, MAX_OBS_DATES must be\n",
      " defined in SNOWMODEL.INC to be greater than the\n",
      " number of observation dates in the entire simulation\n",
      " + (plus) the number of years in the simulation.  For\n",
      " example, for a 6-year simulation with two observation\n",
      " dates in each year, you would set max_obs_dates to be\n",
      " at least = 18.\n",
      "\n",
      "^C\n",
      "mv: cannot stat ‘/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/outputs/wi_assim/swed.gdat’: No such file or directory\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/code\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev\n",
      "\n",
      " For a DATA ASSIMILATION RUN, MAX_OBS_DATES must be\n",
      " defined in SNOWMODEL.INC to be greater than the\n",
      " number of observation dates in the entire simulation\n",
      " + (plus) the number of years in the simulation.  For\n",
      " example, for a 6-year simulation with two observation\n",
      " dates in each year, you would set max_obs_dates to be\n",
      " at least = 18.\n",
      "\n",
      "\n",
      " Checking for sufficient met forcing data to\n",
      "   complete the model simulation.  This may\n",
      "   take a while, depending on how big your met\n",
      "   input file is.\n",
      "\n",
      "\n",
      " You are running the large-domain Barnes oi scheme\n",
      "   This requires:\n",
      "   1) no missing data for the fields of interest\n",
      "   2) no missing stations during the simulation\n",
      "   3) met file must list stations in the same order\n",
      "   4) the number of nearest stations used is 9 or less\n",
      "   5)  **** no error checking for this is done ****\n",
      "\n",
      " Generating nearest-station index.  Be patient.\n",
      "\n",
      "In Assim Loop #1;  WORKING ON MODEL TIME = 2018   9   1   0.0\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      "At line 425 of file ./dataassim_user.f (unit = 238, file = 'outputs/wo_assim/swed.gdat')\n",
      "Fortran runtime error: Non-existing record number\n",
      "mv: cannot stat ‘/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/outputs/wi_assim/swed.gdat’: No such file or directory\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/code\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev\n",
      "\n",
      " For a DATA ASSIMILATION RUN, MAX_OBS_DATES must be\n",
      " defined in SNOWMODEL.INC to be greater than the\n",
      " number of observation dates in the entire simulation\n",
      " + (plus) the number of years in the simulation.  For\n",
      " example, for a 6-year simulation with two observation\n",
      " dates in each year, you would set max_obs_dates to be\n",
      " at least = 18.\n",
      "\n",
      "\n",
      " Checking for sufficient met forcing data to\n",
      "   complete the model simulation.  This may\n",
      "   take a while, depending on how big your met\n",
      "   input file is.\n",
      "\n",
      "\n",
      " You are running the large-domain Barnes oi scheme\n",
      "   This requires:\n",
      "   1) no missing data for the fields of interest\n",
      "   2) no missing stations during the simulation\n",
      "   3) met file must list stations in the same order\n",
      "   4) the number of nearest stations used is 9 or less\n",
      "   5)  **** no error checking for this is done ****\n",
      "\n",
      " Generating nearest-station index.  Be patient.\n",
      "\n",
      "In Assim Loop #1;  WORKING ON MODEL TIME = 2018   9   1   0.0\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      "At line 425 of file ./dataassim_user.f (unit = 238, file = 'outputs/wo_assim/swed.gdat')\n",
      "Fortran runtime error: Non-existing record number\n",
      "mv: cannot stat ‘/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/outputs/wi_assim/swed.gdat’: No such file or directory\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/code\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev\n",
      "\n",
      " For a DATA ASSIMILATION RUN, MAX_OBS_DATES must be\n",
      " defined in SNOWMODEL.INC to be greater than the\n",
      " number of observation dates in the entire simulation\n",
      " + (plus) the number of years in the simulation.  For\n",
      " example, for a 6-year simulation with two observation\n",
      " dates in each year, you would set max_obs_dates to be\n",
      " at least = 18.\n",
      "\n",
      "\n",
      " Checking for sufficient met forcing data to\n",
      "   complete the model simulation.  This may\n",
      "   take a while, depending on how big your met\n",
      "   input file is.\n",
      "\n",
      "\n",
      " You are running the large-domain Barnes oi scheme\n",
      "   This requires:\n",
      "   1) no missing data for the fields of interest\n",
      "   2) no missing stations during the simulation\n",
      "   3) met file must list stations in the same order\n",
      "   4) the number of nearest stations used is 9 or less\n",
      "   5)  **** no error checking for this is done ****\n",
      "\n",
      " Generating nearest-station index.  Be patient.\n",
      "\n",
      "In Assim Loop #1;  WORKING ON MODEL TIME = 2018   9   1   0.0\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      "At line 425 of file ./dataassim_user.f (unit = 238, file = 'outputs/wo_assim/swed.gdat')\n",
      "Fortran runtime error: Non-existing record number\n",
      "mv: cannot stat ‘/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/outputs/wi_assim/swed.gdat’: No such file or directory\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/code\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev\n",
      "\n",
      " For a DATA ASSIMILATION RUN, MAX_OBS_DATES must be\n",
      " defined in SNOWMODEL.INC to be greater than the\n",
      " number of observation dates in the entire simulation\n",
      " + (plus) the number of years in the simulation.  For\n",
      " example, for a 6-year simulation with two observation\n",
      " dates in each year, you would set max_obs_dates to be\n",
      " at least = 18.\n",
      "\n",
      "\n",
      " Checking for sufficient met forcing data to\n",
      "   complete the model simulation.  This may\n",
      "   take a while, depending on how big your met\n",
      "   input file is.\n",
      "\n",
      "\n",
      " You are running the large-domain Barnes oi scheme\n",
      "   This requires:\n",
      "   1) no missing data for the fields of interest\n",
      "   2) no missing stations during the simulation\n",
      "   3) met file must list stations in the same order\n",
      "   4) the number of nearest stations used is 9 or less\n",
      "   5)  **** no error checking for this is done ****\n",
      "\n",
      " Generating nearest-station index.  Be patient.\n",
      "\n",
      "In Assim Loop #1;  WORKING ON MODEL TIME = 2018   9   1   0.0\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      "At line 425 of file ./dataassim_user.f (unit = 238, file = 'outputs/wo_assim/swed.gdat')\n",
      "Fortran runtime error: Non-existing record number\n",
      "mv: cannot stat ‘/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/outputs/wi_assim/swed.gdat’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#assimilate CSO observations into SM\n",
    "SMassim_ensemble(cso_gdf,var,out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run SM for SNOTEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges: [1774.  2062.4 2350.8 2639.2 2927.6 3216. ]\n",
      "labels: [0 1 2 3 4]\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/code\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev\n",
      "\n",
      " For a DATA ASSIMILATION RUN, MAX_OBS_DATES must be\n",
      " defined in SNOWMODEL.INC to be greater than the\n",
      " number of observation dates in the entire simulation\n",
      " + (plus) the number of years in the simulation.  For\n",
      " example, for a 6-year simulation with two observation\n",
      " dates in each year, you would set max_obs_dates to be\n",
      " at least = 18.\n",
      "\n",
      "\n",
      " Checking for sufficient met forcing data to\n",
      "   complete the model simulation.  This may\n",
      "   take a while, depending on how big your met\n",
      "   input file is.\n",
      "\n",
      "\n",
      " You are running the large-domain Barnes oi scheme\n",
      "   This requires:\n",
      "   1) no missing data for the fields of interest\n",
      "   2) no missing stations during the simulation\n",
      "   3) met file must list stations in the same order\n",
      "   4) the number of nearest stations used is 9 or less\n",
      "   5)  **** no error checking for this is done ****\n",
      "\n",
      " Generating nearest-station index.  Be patient.\n",
      "\n",
      "In Assim Loop #1;  WORKING ON MODEL TIME = 2018   9   1   0.0\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      "At line 425 of file ./dataassim_user.f (unit = 238, file = 'outputs/wo_assim/swed.gdat')\n",
      "Fortran runtime error: Non-existing record number\n",
      "mv: cannot stat ‘/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/outputs/wi_assim/swed.gdat’: No such file or directory\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/code\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev\n",
      "\n",
      " For a DATA ASSIMILATION RUN, MAX_OBS_DATES must be\n",
      " defined in SNOWMODEL.INC to be greater than the\n",
      " number of observation dates in the entire simulation\n",
      " + (plus) the number of years in the simulation.  For\n",
      " example, for a 6-year simulation with two observation\n",
      " dates in each year, you would set max_obs_dates to be\n",
      " at least = 18.\n",
      "\n",
      "\n",
      " Checking for sufficient met forcing data to\n",
      "   complete the model simulation.  This may\n",
      "   take a while, depending on how big your met\n",
      "   input file is.\n",
      "\n",
      "\n",
      " You are running the large-domain Barnes oi scheme\n",
      "   This requires:\n",
      "   1) no missing data for the fields of interest\n",
      "   2) no missing stations during the simulation\n",
      "   3) met file must list stations in the same order\n",
      "   4) the number of nearest stations used is 9 or less\n",
      "   5)  **** no error checking for this is done ****\n",
      "\n",
      " Generating nearest-station index.  Be patient.\n",
      "\n",
      "In Assim Loop #1;  WORKING ON MODEL TIME = 2018   9   1   0.0\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      "At line 425 of file ./dataassim_user.f (unit = 238, file = 'outputs/wo_assim/swed.gdat')\n",
      "Fortran runtime error: Non-existing record number\n",
      "mv: cannot stat ‘/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/outputs/wi_assim/swed.gdat’: No such file or directory\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/code\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev\n",
      "\n",
      " For a DATA ASSIMILATION RUN, MAX_OBS_DATES must be\n",
      " defined in SNOWMODEL.INC to be greater than the\n",
      " number of observation dates in the entire simulation\n",
      " + (plus) the number of years in the simulation.  For\n",
      " example, for a 6-year simulation with two observation\n",
      " dates in each year, you would set max_obs_dates to be\n",
      " at least = 18.\n",
      "\n",
      "\n",
      " Checking for sufficient met forcing data to\n",
      "   complete the model simulation.  This may\n",
      "   take a while, depending on how big your met\n",
      "   input file is.\n",
      "\n",
      "\n",
      " You are running the large-domain Barnes oi scheme\n",
      "   This requires:\n",
      "   1) no missing data for the fields of interest\n",
      "   2) no missing stations during the simulation\n",
      "   3) met file must list stations in the same order\n",
      "   4) the number of nearest stations used is 9 or less\n",
      "   5)  **** no error checking for this is done ****\n",
      "\n",
      " Generating nearest-station index.  Be patient.\n",
      "\n",
      "In Assim Loop #1;  WORKING ON MODEL TIME = 2018   9   1   0.0\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      "At line 425 of file ./dataassim_user.f (unit = 238, file = 'outputs/wo_assim/swed.gdat')\n",
      "Fortran runtime error: Non-existing record number\n",
      "mv: cannot stat ‘/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/outputs/wi_assim/swed.gdat’: No such file or directory\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/code\n",
      "/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev\n",
      "\n",
      " For a DATA ASSIMILATION RUN, MAX_OBS_DATES must be\n",
      " defined in SNOWMODEL.INC to be greater than the\n",
      " number of observation dates in the entire simulation\n",
      " + (plus) the number of years in the simulation.  For\n",
      " example, for a 6-year simulation with two observation\n",
      " dates in each year, you would set max_obs_dates to be\n",
      " at least = 18.\n",
      "\n",
      "\n",
      " Checking for sufficient met forcing data to\n",
      "   complete the model simulation.  This may\n",
      "   take a while, depending on how big your met\n",
      "   input file is.\n",
      "\n",
      "\n",
      " You are running the large-domain Barnes oi scheme\n",
      "   This requires:\n",
      "   1) no missing data for the fields of interest\n",
      "   2) no missing stations during the simulation\n",
      "   3) met file must list stations in the same order\n",
      "   4) the number of nearest stations used is 9 or less\n",
      "   5)  **** no error checking for this is done ****\n",
      "\n",
      " Generating nearest-station index.  Be patient.\n",
      "\n",
      "In Assim Loop #1;  WORKING ON MODEL TIME = 2018   9   1   0.0\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      " ZEROING OUT THE SNOW ARRAYS\n",
      "At line 425 of file ./dataassim_user.f (unit = 238, file = 'outputs/wo_assim/swed.gdat')\n",
      "Fortran runtime error: Non-existing record number\n",
      "mv: cannot stat ‘/nfs/attic/dfh/Aragon2/WY_scratch/jan2021_snowmodel-dfhill_elev/outputs/wi_assim/swed.gdat’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#assimilate SNOTEL observations into SM\n",
    "SMassim_ensemble_snotel(cso_gdf,snotel_assim_sites,snotel_swe_assim,var,out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run SM for CSO & SNOTEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assimilate SNOTEL observations into SM\n",
    "SMassim_ensemble_both(snotel_swe_assim,snotel_assim_sites,cso_gdf,var,out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STswe = snotel_swe_assim\n",
    "STmeta = snotel_assim_sites\n",
    "CSOdata = cso_gdf\n",
    "outFpath = 'test.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges: [1774.  2062.4 2350.8 2639.2 2927.6 3216. ]\n",
      "labels: [0 1 2 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var == 'elev'\n",
    "edges = np.histogram_bin_edges(CSOdata.dem_elev,bins=5, range=(CSOdata.dem_elev.min(),CSOdata.dem_elev.max()))\n",
    "print('edges:',edges)\n",
    "labs = np.arange(0,len(edges)-1,1)\n",
    "print('labels:',labs)\n",
    "bins = pd.cut(STmeta['dem_elev'], edges,labels=labs)\n",
    "STmeta['elev_bin']=bins \n",
    "bins = pd.cut(CSOdata['dem_elev'], edges,labels=labs)\n",
    "CSOdata['elev_bin']=bins \n",
    "for lab in labs:\n",
    "    newST = STmeta[STmeta.elev_bin == lab]\n",
    "    newCSO = CSOdata[CSOdata.elev_bin == lab]\n",
    "    newSTswe = STswe[np.intersect1d(STswe.columns, newST.code.values)] \n",
    "    outFpath = 'test_'+str(lab)+'.dat'\n",
    "    num_obs = make_SMassim_file_both(newSTswe,newST,newCSO,outFpath)\n",
    "num_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = 'M'\n",
    "newST = STmeta\n",
    "mo = [11,12,1,2,3,4,5]#np.unique(STswe.index.month)\n",
    "for m in mo:\n",
    "    newSTswe = STswe[STswe.index.month == m]\n",
    "    newCSO = CSOdata[CSOdata[var] == m]       \n",
    "    outFpath = 'test_'+str(m)+'.dat'\n",
    "    num_obs = make_SMassim_file_both(newSTswe,newST,newCSO,outFpath)\n",
    "num_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_SMassim_file_both(STswe,STmeta,CSOdata,outFpath):\n",
    "\n",
    "    f= open(outFpath,\"w+\")\n",
    "    \n",
    "    #determine number of days with observations to assimilate\n",
    "    if STswe.shape[1]>0:\n",
    "        uq_day = np.unique(np.concatenate((STswe.index.date,CSOdata.dt.dt.date.values)))\n",
    "        f.write('{:02.0f}\\n'.format(len(uq_day)))\n",
    "    else:\n",
    "        uq_day = np.unique(CSOdata.dt.dt.date.values)\n",
    "        f.write('{:02.0f}\\n'.format(len(uq_day)))\n",
    "    \n",
    "    # determine snotel stations \n",
    "    stn = list(STswe.columns)\n",
    "    \n",
    "    # ids for CSO observations - outside of loop so each observation is unique\n",
    "    IDS = 500\n",
    "    \n",
    "    #add assimilation observations to output file\n",
    "    for i in range(len(uq_day)):\n",
    "\n",
    "        SThoy = STswe[STswe.index.date == uq_day[i]]\n",
    "        CSOhoy = CSOdata[CSOdata.dt.dt.date.values == uq_day[i]]\n",
    "\n",
    "        d=uq_day[i].day\n",
    "        m=uq_day[i].month\n",
    "        y=uq_day[i].year\n",
    "\n",
    "        date = str(y)+' '+str(m)+' '+str(d)\n",
    "\n",
    "        stn_count = len(stn) + len(CSOhoy)\n",
    "        \n",
    "        if stn_count > 0:\n",
    "            f.write(date+' \\n')\n",
    "            f.write(str(stn_count)+' \\n')\n",
    "\n",
    "        #go through snotel stations for that day \n",
    "        ids = 100\n",
    "        if len(SThoy) > 0:\n",
    "            for k in stn:\n",
    "                ids = ids + 1 \n",
    "                x = STmeta.easting.values[STmeta.code.values == k][0]\n",
    "                y = STmeta.northing.values[STmeta.code.values == k][0]\n",
    "                swe = SThoy[k].values[0]\n",
    "                f.write('{:3.0f}\\t'.format(ids)+'{:10.0f}\\t'.format(x)+'{:10.0f}\\t'.format(y)+'{:3.2f}\\n'.format(swe))    \n",
    "        #go through cso obs for that day \n",
    "        if len(CSOhoy) > 0:\n",
    "            for c in range(len(CSOhoy)):\n",
    "                IDS = IDS + 1 \n",
    "                x= CSOhoy.x[CSOhoy.index[c]]\n",
    "                y=CSOhoy.y[CSOhoy.index[c]]\n",
    "                swe=CSOhoy.swe[CSOhoy.index[c]]\n",
    "                f.write('{:3.0f}\\t'.format(IDS)+'{:10.0f}\\t'.format(x)+'{:10.0f}\\t'.format(y)+'{:3.2f}\\n'.format(swe))\n",
    "    f.close()\n",
    "    return len(uq_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_SMassim_file_both(STswe,STmeta,CSOdata,outFpath):\n",
    "\n",
    "    f= open(outFpath,\"w+\")\n",
    "    uq_day = np.unique(np.concatenate((STswe.index.date,CSOdata.dt.dt.date.values)))\n",
    "    f.write('{:02.0f}\\n'.format(len(uq_day)))\n",
    "\n",
    "    stn = list(STswe.columns)\n",
    "\n",
    "    for i in range(len(uq_day)):\n",
    "\n",
    "        SThoy = STswe[STswe.index.date == uq_day[i]]\n",
    "        CSOhoy = CSOdata[CSOdata.dt.dt.date.values == uq_day[i]]\n",
    "\n",
    "        d=uq_day[i].day\n",
    "        m=uq_day[i].month\n",
    "        y=uq_day[i].year\n",
    "\n",
    "        date = str(y)+' '+str(m)+' '+str(d)\n",
    "\n",
    "        stn_count = len(stn) + len(CSOhoy)\n",
    "\n",
    "        f.write(date+' \\n')\n",
    "        f.write(str(stn_count)+' \\n')\n",
    "\n",
    "        #go through snotel stations for that day \n",
    "        ids = 100\n",
    "        if len(SThoy) > 0:\n",
    "            for k in stn:\n",
    "                ids = ids + 1 \n",
    "                x = STmeta.easting.values[STmeta.code.values == k][0]\n",
    "                y = STmeta.northing.values[STmeta.code.values == k][0]\n",
    "                swe = SThoy[k].values[0]\n",
    "                f.write('{:3.0f}\\t'.format(ids)+'{:10.0f}\\t'.format(x)+'{:10.0f}\\t'.format(y)+'{:3.2f}\\n'.format(swe))    \n",
    "        #go through cso obs for that day \n",
    "        if len(CSOhoy) > 0:\n",
    "            for c in range(len(CSOhoy)):\n",
    "                ids = ids + 1 \n",
    "                x= CSOhoy.x[CSOhoy.index[c]]\n",
    "                y=CSOhoy.y[CSOhoy.index[c]]\n",
    "                swe=CSOhoy.swe[CSOhoy.index[c]]\n",
    "                f.write('{:3.0f}\\t'.format(ids)+'{:10.0f}\\t'.format(x)+'{:10.0f}\\t'.format(y)+'{:3.2f}\\n'.format(swe))\n",
    "    f.close()\n",
    "    return len(uq_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMassim_ensemble_both(STswe,STmeta,CSOdata,var,path):\n",
    "    '''\n",
    "    STmeta: this is the geodataframe containing all snotel stations\n",
    "    STswe: this is a dataframe containing all snotel swe\n",
    "    CSOdata: this is the geodataframe containing all CSO data    \n",
    "    var: this is the landscape characteristic that will be made into an assimilation ensemble \n",
    "        'all': assimilate all inputs to SM\n",
    "        'elev': assimilate each of n elevation bands. \n",
    "            Default = breaks elevation range into 5 bands\n",
    "        'slope': assimilate each of n slope bands. \n",
    "            Default = breaks slope range into 5 bands\n",
    "        'tc': assimilate each of n terrain complexity score bands. \n",
    "            Default = breaks tc score range into 5 bands\n",
    "        'delta_day': sets a minimum number of days between assimilated observations. \n",
    "            -> only 1 observation is selected each day\n",
    "        'M': assimilate data from each month\n",
    "        'lc': assimilate data from each land cover class\n",
    "        'aspect': assimilate data from each aspect N, E, S, W\n",
    "    path: path to put all output SM .gdat files\n",
    "    '''\n",
    "\n",
    "    #create directory with initiation date for ensemble if it doesn't exist\n",
    "    !mkdir -p $path\n",
    "    outFpath = SMpath+'swe_assim/swe_obs_test.dat'\n",
    "    if var == 'all':\n",
    "        newST = STmeta\n",
    "        newSTswe = STswe\n",
    "        newCSO = CSOdata\n",
    "        num_obs = make_SMassim_file_both(newSTswe,newST,newCSO,outFpath)\n",
    "        #edit .inc file\n",
    "        replace_line(incFile, 30, '      parameter (max_obs_dates='+str(num_obs+1)+')\\n')\n",
    "        #compile SM        \n",
    "        %cd $codepath\n",
    "        ! ./compile_snowmodel.script\n",
    "        #run snowmodel \n",
    "        %cd $SMpath\n",
    "        ! ./snowmodel\n",
    "        #move swed.gdat file \n",
    "        oSWEpath = SMpath + 'outputs/wi_assim/swed.gdat'\n",
    "        nSWEpath = path + '/snotel_all_swed.gdat'\n",
    "        !mv $oSWEpath $nSWEpath     \n",
    "        \n",
    "        \n",
    "    elif var == 'elev':\n",
    "        edges = np.histogram_bin_edges(CSOdata.dem_elev,bins=5, range=(CSOdata.dem_elev.min(),CSOdata.dem_elev.max()))\n",
    "        print('edges:',edges)\n",
    "        labs = np.arange(0,len(edges)-1,1)\n",
    "        print('labels:',labs)\n",
    "        bins = pd.cut(STmeta['dem_elev'], edges,labels=labs)\n",
    "        STmeta['elev_bin']=bins \n",
    "        bins = pd.cut(CSOdata['dem_elev'], edges,labels=labs)\n",
    "        CSOdata['elev_bin']=bins \n",
    "        for lab in labs:\n",
    "            newST = STmeta[STmeta.elev_bin == lab]\n",
    "            newCSO = CSOdata[CSOdata.elev_bin == lab]\n",
    "            newSTswe = STswe[np.intersect1d(STswe.columns, newST.code.values)] \n",
    "            num_obs = make_SMassim_file_both(newSTswe,newST,newCSO,outFpath)\n",
    "            #edit .inc file\n",
    "            replace_line(incFile, 30, '      parameter (max_obs_dates='+str(num_obs+1)+')\\n')\n",
    "            #compile SM\n",
    "            %cd $codepath\n",
    "            ! ./compile_snowmodel.script\n",
    "            #run snowmodel \n",
    "            %cd $SMpath\n",
    "            ! ./snowmodel\n",
    "            #move swed.gdat file \n",
    "            oSWEpath = SMpath + 'outputs/wi_assim/swed.gdat'\n",
    "            nSWEpath = path + '/snotel_elev_'+str(lab)+'_swed.gdat'\n",
    "            !mv $oSWEpath $nSWEpath                  \n",
    "        \n",
    "            \n",
    "            \n",
    "    elif var == 'slope':\n",
    "        edges = np.histogram_bin_edges(CSOdata.slope,bins=5, range=(CSOdata.slope.min(),CSOdata.slope.max()))\n",
    "        print('edges:',edges)\n",
    "        labs = np.arange(0,len(edges)-1,1)\n",
    "        print('labels:',labs)\n",
    "        bins = pd.cut(STmeta['slope'], edges,labels=labs)\n",
    "        STmeta['slope_bin']=bins \n",
    "        bins = pd.cut(CSOdata['slope'], edges,labels=labs)\n",
    "        CSOdata['slope_bin']=bins   \n",
    "        for lab in labs:\n",
    "            newST = STmeta[STmeta.slope_bin == lab]\n",
    "            newCSO = CSOdata[CSOdata.slope_bin == lab]\n",
    "            newSTswe = STswe[np.intersect1d(STswe.columns, newST.code.values)] \n",
    "            num_obs = make_SMassim_file_both(newSTswe,newST,newCSO,outFpath)\n",
    "            #edit .inc file\n",
    "            replace_line(incFile, 30, '      parameter (max_obs_dates='+str(num_obs+1)+')\\n')\n",
    "            #compile SM\n",
    "            %cd $codepath\n",
    "            ! ./compile_snowmodel.script\n",
    "            #run snowmodel \n",
    "            %cd $SMpath\n",
    "            ! ./snowmodel\n",
    "            #move swed.gdat file \n",
    "            oSWEpath = SMpath + 'outputs/wi_assim/swed.gdat'\n",
    "            nSWEpath = path + '/snotel_slope_'+str(lab)+'_swed.gdat'\n",
    "            !mv $oSWEpath $nSWEpath                                 \n",
    "\n",
    "    elif var == 'tc':\n",
    "        edges = np.histogram_bin_edges(CSOdata.tc,bins=5, range=(CSOdata.tc.min(),CSOdata.tc.max()))\n",
    "        print('edges:',edges)\n",
    "        labs = np.arange(0,len(edges)-1,1)\n",
    "        print('labels:',labs)\n",
    "        bins = pd.cut(STmeta['tc'], edges,labels=labs)\n",
    "        STmeta['tc_bin']=bins \n",
    "        bins = pd.cut(CSOdata['tc'], edges,labels=labs)\n",
    "        CSOdata['tc_bin']=bins \n",
    "        for lab in labs:\n",
    "            newST = STmeta[STmeta.tc_bin == lab]\n",
    "            newCSO = CSOdata[CSOdata.tc_bin == lab]\n",
    "            newSTswe = STswe[np.intersect1d(STswe.columns, newST.code.values)] \n",
    "            num_obs = make_SMassim_file_both(newSTswe,newST,newCSO,outFpath)\n",
    "            #edit .inc file\n",
    "            replace_line(incFile, 30, '      parameter (max_obs_dates='+str(num_obs+1)+')\\n')\n",
    "            #compile SM\n",
    "            %cd $codepath\n",
    "            ! ./compile_snowmodel.script\n",
    "            #run snowmodel \n",
    "            %cd $SMpath\n",
    "            ! ./snowmodel\n",
    "            #move swed.gdat file \n",
    "            oSWEpath = SMpath + 'outputs/wi_assim/swed.gdat'\n",
    "            nSWEpath = path + '/snotel_tc_'+str(lab)+'_swed.gdat'\n",
    "            !mv $oSWEpath $nSWEpath     \n",
    "          \n",
    "            \n",
    "    elif var == 'delta_day':\n",
    "        import datetime\n",
    "        CSOdata = CSOdata.sort_values(by='dt',ascending=True)\n",
    "        CSOdata = CSOdata.reset_index(drop=True)        \n",
    "        newST = STmeta\n",
    "        Delta = [3,5,7,10]\n",
    "        for dels in Delta:\n",
    "            idx = [0]\n",
    "            st = CSOdata.dt[0]\n",
    "            for i in range(1,len(CSOdata)-1):\n",
    "                date = CSOdata.dt.iloc[i]\n",
    "                gap = (date - st).days\n",
    "                if gap<=dels:\n",
    "                    continue \n",
    "                else:\n",
    "                    idx.append(i)\n",
    "                    st = date\n",
    "            newCSO = CSOdata[CSOdata.index.isin(idx)]\n",
    "            newSTswe = STswe.iloc[::dels,:]\n",
    "            num_obs = make_SMassim_file_both(newSTswe,newST,newCSO,outFpath)\n",
    "            #edit .inc file\n",
    "            replace_line(incFile, 30, '      parameter (max_obs_dates='+str(num_obs+1)+')\\n')\n",
    "            #compile SM\n",
    "            %cd $codepath\n",
    "            ! ./compile_snowmodel.script\n",
    "            #run snowmodel \n",
    "            %cd $SMpath\n",
    "            ! ./snowmodel\n",
    "            #move swed.gdat file \n",
    "            oSWEpath = SMpath + 'outputs/wi_assim/swed.gdat'\n",
    "            nSWEpath = path + '/snotel_day_delta'+str(dels)+'_swed.gdat'\n",
    "            !mv $oSWEpath $nSWEpath            \n",
    "            \n",
    "            \n",
    "    elif var == 'M':\n",
    "        newST = STmeta\n",
    "        mo = [11,12,1,2,3,4,5]#np.unique(STswe.index.month)\n",
    "        for m in mo:\n",
    "            newSTswe = STswe[STswe.index.month == m]\n",
    "            newCSO = CSOdata[CSOdata[var] == m]            \n",
    "            num_obs = make_SMassim_file_both(newSTswe,newST,newCSO,outFpath)\n",
    "            #edit .inc file\n",
    "            replace_line(incFile, 30, '      parameter (max_obs_dates='+str(num_obs+1)+')\\n')\n",
    "            #compile SM\n",
    "            %cd $codepath\n",
    "            ! ./compile_snowmodel.script\n",
    "            #run snowmodel \n",
    "            %cd $SMpath\n",
    "            ! ./snowmodel\n",
    "            #move swed.gdat file \n",
    "            oSWEpath = SMpath + 'outputs/wi_assim/swed.gdat'\n",
    "            nSWEpath = path + '/snotel_M_'+str(m)+'_swed.gdat'\n",
    "            !mv $oSWEpath $nSWEpath  \n",
    "\n",
    "            \n",
    "            \n",
    "    else: #works for 'M', 'lc', 'aspect'\n",
    "        uq = np.unique(np.concatenate((STmeta[var].values,CSOdata[var].values)))\n",
    "        for lab in uq:\n",
    "            newST = STmeta[STmeta[var] == lab]\n",
    "            newCSO = CSOdata[CSOdata[var] == lab]\n",
    "            newSTswe = STswe[np.intersect1d(STswe.columns, newST.code.values)] \n",
    "            num_obs = make_SMassim_file_both(newSTswe,newST,newCSO,outFpath)\n",
    "            #edit .inc file\n",
    "            replace_line(incFile, 30, '      parameter (max_obs_dates='+str(num_obs+1)+')\\n')\n",
    "            #compile SM\n",
    "            %cd $codepath\n",
    "            ! ./compile_snowmodel.script\n",
    "            #run snowmodel \n",
    "            %cd $SMpath\n",
    "            ! ./snowmodel\n",
    "            #move swed.gdat file \n",
    "            oSWEpath = SMpath + 'outputs/wi_assim/swed.gdat'\n",
    "            nSWEpath = path + '/snotel_'+var+'_'+str(lab)+'_swed.gdat'\n",
    "            !mv $oSWEpath $nSWEpath     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snowmodelcal]",
   "language": "python",
   "name": "conda-env-snowmodelcal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
